{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test OpenAI GPT Transliteration vs Sarvam AI\n",
    "\n",
    "Compare OpenAI GPT-based transliteration against Sarvam AI's specialized transliteration service.\n",
    "\n",
    "**Models tested:**\n",
    "- `gpt-4o-mini` - Cost-efficient model\n",
    "- Sarvam AI transliteration API\n",
    "\n",
    "**Evaluation criteria:**\n",
    "1. Romanization accuracy\n",
    "2. Consistency across segments\n",
    "3. Cost per character\n",
    "4. Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from src.voice_eval.sarvam_api import transliterate_text, get_sarvam_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys\n",
    "load_dotenv()\n",
    "openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "sarvam_key = get_sarvam_api_key()\n",
    "print(\"âœ“ API keys loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data: Sample Kannada Text\n",
    "\n",
    "Using transcription from previous Whisper API test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Kannada text from Whisper transcription\n",
    "# This is from the shortest segment for quick testing\n",
    "test_text_short = \"à²‡à²²à³à²²à²¿ à²¬à³‡à²°à³† à²•à²¡à³† à²…à²¦à²¾à²¨à³à²°à²¿. à²¹à³Œà²¦à³à²°à²¿ à²…à²•à³à²•à²¿ à²²à³†à²•à³à²• à²¹à³‡à²³à³à²¤à²¿à²¦à³à²°à²¿ à²…à²¦à²•à³à²•à³à²°à²¿.\"\n",
    "\n",
    "# Longer segment for better comparison\n",
    "test_text_long = \"\"\"à²ªà³à²°à²¦à²¿à²ªà²¦à²¾à²¨à³à²¨à³ à²¨à²¿à²µà³ à²…à²µà²¨à³à²¨à³ à²¬à²¾à²œà³‹à²•à³à²•à²¾à²²à³à²²à³‡ à²•à³à²¤à³à²¤à³à²—à²¾à²°à²¿. à²‡à²¦à³† à²—à²£à²¿à²¤ à²—à²£à²•à³à²•à²¾à²‚à²¤à²•à²‚à²¤à²¾ à²’à²‚à²¦à³ à²¹à²¸à²¾à²¯à²¿ à²¯à³‹à²œà²¨à³†à²°à²¿à²¦à³†. \n",
    "à²®à³‚à²°à³ à²¨à²¾à²•à³ à²…à²¯à²¿à²¨à³† à²¤à²°à²—à²¤à²¿ à²®à²•à³à²•à²³à³†à²—à³† à²¯à²¾à²°à³ à²¸à²²à³à²ª à²®à²¾à²•à³à²•à²¾à²°à²¦à²²à³à²²à²¿ à²’à²‚à²¦à³ à²¤à²¨à²¾à²¯à²¿ à²¯à³‹à²œà²¨à³†à²°à²¿à²¦à³†.\"\"\"\n",
    "\n",
    "print(f\"Short test: {len(test_text_short)} characters\")\n",
    "print(f\"Long test: {len(test_text_long)} characters\")\n",
    "print(f\"\\nKannada text (short):\\n{test_text_short}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: OpenAI GPT-4o-mini Transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate_with_gpt(\n",
    "    text: str,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    system_prompt: str = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Transliterate Kannada text to Roman script using OpenAI GPT.\n",
    "    \n",
    "    Returns dict with:\n",
    "    - transliterated_text: The romanized output\n",
    "    - model: Model used\n",
    "    - tokens: Token usage\n",
    "    - latency_ms: Response time in milliseconds\n",
    "    - estimated_cost_usd: Cost estimate\n",
    "    \"\"\"\n",
    "    if system_prompt is None:\n",
    "        system_prompt = (\n",
    "            \"You are a Kannada language expert specializing in transliteration. \"\n",
    "            \"Transliterate the provided Kannada text to Roman/Latin script. \"\n",
    "            \"Use standard phonetic romanization that is readable and pronounceable. \"\n",
    "            \"Preserve the original meaning and pronunciation as closely as possible. \"\n",
    "            \"Only output the transliterated text, no explanations.\"\n",
    "        )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ],\n",
    "        temperature=0.0  # Deterministic output\n",
    "    )\n",
    "    \n",
    "    latency_ms = (time.time() - start_time) * 1000\n",
    "    \n",
    "    # Extract token usage and calculate cost\n",
    "    # GPT-4o-mini pricing: $0.15 per 1M input tokens, $0.60 per 1M output tokens\n",
    "    input_tokens = response.usage.prompt_tokens\n",
    "    output_tokens = response.usage.completion_tokens\n",
    "    cost_usd = (input_tokens * 0.15 / 1_000_000) + (output_tokens * 0.60 / 1_000_000)\n",
    "    \n",
    "    return {\n",
    "        \"transliterated_text\": response.choices[0].message.content.strip(),\n",
    "        \"model\": model,\n",
    "        \"tokens\": {\n",
    "            \"input\": input_tokens,\n",
    "            \"output\": output_tokens,\n",
    "            \"total\": response.usage.total_tokens\n",
    "        },\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"estimated_cost_usd\": cost_usd\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing OpenAI GPT-4o-mini (short text)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "gpt_result_short = transliterate_with_gpt(test_text_short)\n",
    "\n",
    "print(f\"\\nOriginal (Kannada):\\n{test_text_short}\")\n",
    "print(f\"\\nTransliterated (GPT-4o-mini):\\n{gpt_result_short['transliterated_text']}\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  Latency: {gpt_result_short['latency_ms']:.0f}ms\")\n",
    "print(f\"  Tokens: {gpt_result_short['tokens']['total']} (in: {gpt_result_short['tokens']['input']}, out: {gpt_result_short['tokens']['output']})\")\n",
    "print(f\"  Cost: ${gpt_result_short['estimated_cost_usd']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Sarvam AI Transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing Sarvam AI (short text)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "start_time = time.time()\n",
    "sarvam_result_short = transliterate_text(\n",
    "    text=test_text_short,\n",
    "    api_key=sarvam_key,\n",
    "    source_language_code=\"kn-IN\"\n",
    ")\n",
    "sarvam_latency_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"\\nOriginal (Kannada):\\n{test_text_short}\")\n",
    "print(f\"\\nTransliterated (Sarvam AI):\\n{sarvam_result_short}\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  Latency: {sarvam_latency_ms:.0f}ms\")\n",
    "print(f\"  Cost: Unknown (Sarvam pricing not publicly listed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side-by-Side Comparison (Short Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: Short Text\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOriginal (Kannada):\")\n",
    "print(f\"  {test_text_short}\")\n",
    "print(f\"\\nGPT-4o-mini:\")\n",
    "print(f\"  {gpt_result_short['transliterated_text']}\")\n",
    "print(f\"\\nSarvam AI:\")\n",
    "print(f\"  {sarvam_result_short}\")\n",
    "print(f\"\\nLatency:\")\n",
    "print(f\"  GPT-4o-mini: {gpt_result_short['latency_ms']:.0f}ms\")\n",
    "print(f\"  Sarvam AI:   {sarvam_latency_ms:.0f}ms\")\n",
    "print(f\"\\nCost per character (GPT-4o-mini):\")\n",
    "print(f\"  ${gpt_result_short['estimated_cost_usd'] / len(test_text_short):.8f} per char\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Test: Longer Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Testing with longer text segment\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# GPT-4o-mini\n",
    "gpt_result_long = transliterate_with_gpt(test_text_long)\n",
    "\n",
    "# Sarvam AI\n",
    "start_time = time.time()\n",
    "sarvam_result_long = transliterate_text(\n",
    "    text=test_text_long,\n",
    "    api_key=sarvam_key,\n",
    "    source_language_code=\"kn-IN\"\n",
    ")\n",
    "sarvam_latency_long_ms = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"\\nText length: {len(test_text_long)} characters\")\n",
    "print(f\"\\n\" + \"-\" * 60)\n",
    "print(\"GPT-4o-mini output:\")\n",
    "print(\"-\" * 60)\n",
    "print(gpt_result_long['transliterated_text'])\n",
    "print(f\"\\nLatency: {gpt_result_long['latency_ms']:.0f}ms\")\n",
    "print(f\"Tokens: {gpt_result_long['tokens']['total']}\")\n",
    "print(f\"Cost: ${gpt_result_long['estimated_cost_usd']:.6f}\")\n",
    "\n",
    "print(f\"\\n\" + \"-\" * 60)\n",
    "print(\"Sarvam AI output:\")\n",
    "print(\"-\" * 60)\n",
    "print(sarvam_result_long)\n",
    "print(f\"\\nLatency: {sarvam_latency_long_ms:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Projection for Full Dataset\n",
    "\n",
    "Estimate costs for processing all 42 audio files (~9 hours of transcription)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rough estimate: Assume average transcription produces ~50 chars per second of audio\n",
    "# Dataset: 9 hours = 32,400 seconds\n",
    "# Estimated total Kannada characters: ~1,620,000 chars\n",
    "\n",
    "dataset_duration_seconds = 9 * 3600\n",
    "estimated_chars_per_second = 50  # Conservative estimate\n",
    "estimated_total_chars = dataset_duration_seconds * estimated_chars_per_second\n",
    "\n",
    "# GPT cost per character (based on longer text test)\n",
    "gpt_cost_per_char = gpt_result_long['estimated_cost_usd'] / len(test_text_long)\n",
    "gpt_total_cost = estimated_total_chars * gpt_cost_per_char\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COST PROJECTION: Full Dataset (42 files, 9 hours)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nEstimated total characters: {estimated_total_chars:,}\")\n",
    "print(f\"\\nGPT-4o-mini transliteration:\")\n",
    "print(f\"  Cost per character: ${gpt_cost_per_char:.8f}\")\n",
    "print(f\"  Estimated total cost: ${gpt_total_cost:.4f}\")\n",
    "print(f\"\\nSarvam AI transliteration:\")\n",
    "print(f\"  Cost: Unknown (pricing not publicly available)\")\n",
    "print(f\"\\nFor reference:\")\n",
    "print(f\"  Whisper API transcription cost: ~$3.24 (for 9 hours)\")\n",
    "print(f\"  Combined (Whisper + GPT): ~${3.24 + gpt_total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nâœ“ Both services successfully transliterate Kannada to Roman script\")\n",
    "print(\"\\nðŸ“Š Key Differences:\")\n",
    "print(\"\\n1. Quality:\")\n",
    "print(\"   - Compare outputs above for readability and accuracy\")\n",
    "print(\"   - GPT may be more flexible with custom prompts\")\n",
    "print(\"   - Sarvam is specialized for Indian languages\")\n",
    "print(\"\\n2. Latency:\")\n",
    "print(f\"   - GPT-4o-mini: ~{gpt_result_short['latency_ms']:.0f}ms (short), ~{gpt_result_long['latency_ms']:.0f}ms (long)\")\n",
    "print(f\"   - Sarvam AI:   ~{sarvam_latency_ms:.0f}ms (short), ~{sarvam_latency_long_ms:.0f}ms (long)\")\n",
    "print(\"\\n3. Cost (estimated):\")\n",
    "print(f\"   - GPT-4o-mini: ~${gpt_total_cost:.2f} for full dataset\")\n",
    "print(\"   - Sarvam AI:   Unknown\")\n",
    "print(\"\\n4. Integration:\")\n",
    "print(\"   - GPT: Single API (OpenAI) for both transcription + transliteration\")\n",
    "print(\"   - Sarvam: Separate API, but specialized for Indic languages\")\n",
    "print(\"\\nðŸ’¡ Recommendation: Review outputs above to assess quality difference before deciding.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yi-voice-eval",
   "language": "python",
   "name": "yi-voice-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
