{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Test Whisper API + Sarvam Transliteration Pipeline\n",
    "\n",
    "This notebook tests the full pipeline:\n",
    "1. Transcribe audio with OpenAI Whisper API (Kannada script)\n",
    "2. Transliterate to Roman script using Sarvam AI\n",
    "3. Save both versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from src.voice_eval.config import load_config\n",
    "from src.voice_eval.storage import write_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')\n",
    "sarvam_key = os.getenv('SARVAM_API_KEY')\n",
    "\n",
    "if not openai_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env file\")\n",
    "if not sarvam_key:\n",
    "    raise ValueError(\"SARVAM_API_KEY not found in .env file\")\n",
    "\n",
    "openai_client = OpenAI(api_key=openai_key)\n",
    "print(\"✓ API keys loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "language = load_config('whisper', 'language')\n",
    "audio_dir = load_config('input', 'audio_dir')\n",
    "\n",
    "print(f\"Language: {language}\")\n",
    "print(f\"Audio directory: {audio_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick an MP3 file for testing\n",
    "test_file = f\"{audio_dir}/GHPS.  Bammanakatti.mp3\"\n",
    "print(f\"Test file: {test_file}\")\n",
    "\n",
    "# Check file size\n",
    "file_size_mb = os.path.getsize(test_file) / (1024 * 1024)\n",
    "print(f\"File size: {file_size_mb:.2f} MB (limit: 25 MB) ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 1: Transcribe with Whisper API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: Transcribing with OpenAI Whisper API...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with open(test_file, 'rb') as audio_file:\n",
    "    transcript = openai_client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\",\n",
    "        file=audio_file,\n",
    "        language=language,\n",
    "        response_format=\"verbose_json\",\n",
    "        timestamp_granularities=[\"segment\"]\n",
    "    )\n",
    "\n",
    "print(f\"✓ Transcription complete!\")\n",
    "print(f\"  Language detected: {transcript.language}\")\n",
    "print(f\"  Duration: {transcript.duration:.2f} seconds\")\n",
    "print(f\"  Segments: {len(transcript.segments)}\")\n",
    "print(f\"\\nFirst 200 chars (Kannada script):\\n{transcript.text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 2: Transliterate with Sarvam AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: Transliterating to Roman script with Sarvam AI...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "transliterate_url = \"https://api.sarvam.ai/transliterate\"\n",
    "transliterate_headers = {\n",
    "    \"api-subscription-key\": sarvam_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Transliterate full text\n",
    "transliterate_payload = {\n",
    "    \"input\": transcript.text,\n",
    "    \"source_language_code\": \"kn-IN\",\n",
    "    \"target_language_code\": \"en-IN\"\n",
    "}\n",
    "\n",
    "transliterate_response = requests.post(\n",
    "    transliterate_url,\n",
    "    headers=transliterate_headers,\n",
    "    json=transliterate_payload\n",
    ")\n",
    "\n",
    "if transliterate_response.status_code == 200:\n",
    "    transliterate_result = transliterate_response.json()\n",
    "    romanized_text = transliterate_result.get('transliterated_text', '')\n",
    "    print(f\"✓ Transliteration complete!\")\n",
    "    print(f\"\\nFirst 200 chars (Romanized):\\n{romanized_text[:200]}...\")\n",
    "else:\n",
    "    print(f\"✗ Transliteration failed: {transliterate_response.status_code}\")\n",
    "    print(transliterate_response.text)\n",
    "    romanized_text = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 3: Transliterate Each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: Transliterating individual segments...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "romanized_segments = []\n",
    "\n",
    "for i, segment in enumerate(transcript.segments, 1):\n",
    "    # Transliterate each segment's text\n",
    "    payload = {\n",
    "        \"input\": segment.text,\n",
    "        \"source_language_code\": \"kn-IN\",\n",
    "        \"target_language_code\": \"en-IN\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\n",
    "        transliterate_url,\n",
    "        headers=transliterate_headers,\n",
    "        json=payload\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        romanized_segment_text = result.get('transliterated_text', segment.text)\n",
    "    else:\n",
    "        print(f\"  Warning: Segment {i} transliteration failed, keeping original\")\n",
    "        romanized_segment_text = segment.text\n",
    "    \n",
    "    romanized_segments.append({\n",
    "        \"id\": segment.id,\n",
    "        \"start\": segment.start,\n",
    "        \"end\": segment.end,\n",
    "        \"text_kannada\": segment.text,\n",
    "        \"text_romanized\": romanized_segment_text,\n",
    "        \"tokens\": segment.tokens,\n",
    "        \"temperature\": segment.temperature,\n",
    "        \"avg_logprob\": segment.avg_logprob,\n",
    "        \"compression_ratio\": segment.compression_ratio,\n",
    "        \"no_speech_prob\": segment.no_speech_prob\n",
    "    })\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"  Processed {i}/{len(transcript.segments)} segments...\")\n",
    "\n",
    "print(f\"✓ All {len(romanized_segments)} segments transliterated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 4: Save Combined Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: Saving results...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create combined response\n",
    "combined_response = {\n",
    "    \"metadata\": {\n",
    "        \"file\": test_file,\n",
    "        \"language\": transcript.language,\n",
    "        \"duration\": transcript.duration,\n",
    "        \"whisper_model\": \"whisper-1\",\n",
    "        \"transliteration_provider\": \"sarvam-ai\"\n",
    "    },\n",
    "    \"transcription\": {\n",
    "        \"text_kannada\": transcript.text,\n",
    "        \"text_romanized\": romanized_text\n",
    "    },\n",
    "    \"segments\": romanized_segments\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "output_path = write_file(\n",
    "    \"whisper_sarvam_combined_response.json\",\n",
    "    json.dumps(combined_response, indent=2, ensure_ascii=False),\n",
    "    base_dir=\"files/transcriptions/whisper_sarvam_test\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Combined results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 5: Display Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE SEGMENTS (First 3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, seg in enumerate(romanized_segments[:3], 1):\n",
    "    print(f\"\\n[Segment {i}] {seg['start']:.2f}s → {seg['end']:.2f}s\")\n",
    "    print(f\"  Kannada:    {seg['text_kannada']}\")\n",
    "    print(f\"  Romanized:  {seg['text_romanized']}\")\n",
    "\n",
    "print(f\"\\n... ({len(romanized_segments) - 3} more segments)\")\n",
    "print(\"\\n✅ Pipeline test successful!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yi-voice-eval)",
   "language": "python",
   "name": "yi-voice-eval"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
