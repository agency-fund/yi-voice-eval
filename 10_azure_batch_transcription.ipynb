{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Speech Service Batch Transcription\n",
    "\n",
    "This notebook tests Azure's Batch Transcription REST API for Kannada speech-to-text.\n",
    "\n",
    "## Key Features Being Tested\n",
    "\n",
    "1. **Kannada (kn-IN) support** - Basic transcription quality\n",
    "2. **Diarization** - Speaker separation (tutor vs. child)\n",
    "3. **Word-level timestamps** - For alignment with Whisper baseline\n",
    "4. **Cost tracking** - Compare with OpenAI Whisper pricing\n",
    "\n",
    "## Test Strategy\n",
    "\n",
    "- **Test 1**: Single short file WITHOUT diarization (baseline)\n",
    "- **Test 2**: Same file WITH diarization (check Kannada support)\n",
    "- **Test 3**: Process all 40 files (if diarization works)\n",
    "\n",
    "## Expected Outcome\n",
    "\n",
    "- Transcription results in `files/transcriptions/azure_batch/`\n",
    "- JSON format matching Whisper output structure\n",
    "- Cost comparison: Azure (~$9 for 9 hours) vs. Whisper ($2.67)\n",
    "- **Bonus**: Speaker labels if diarization works for Kannada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path().resolve().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "from voice_eval.azure_batch_api import AzureBatchTranscription, transcribe_audio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(project_root / '.env')\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"‚úì Azure Region: {os.getenv('AZURE_REGION')}\")\n",
    "print(f\"‚úì Storage Account: {os.getenv('AZURE_STORAGE_BUCKET_NAME')}\")\n",
    "print(f\"‚úì Container: {os.getenv('AZURE_STORAGE_CONTAINER_NAME')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for transcription results\n",
    "output_dir = project_root / 'files' / 'transcriptions' / 'azure_batch'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Single File WITHOUT Diarization (Baseline)\n",
    "\n",
    "Test basic Kannada transcription without speaker separation.\n",
    "\n",
    "**Test file**: `+919742536994_3_converted.mp3` (10 seconds, shortest file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize client\n",
    "client = AzureBatchTranscription()\n",
    "\n",
    "# Test with shortest file (10 seconds)\n",
    "test_file = \"+919742536994_3_converted.mp3\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 1: Basic Transcription (NO Diarization)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    result_no_diarization = client.transcribe_file(\n",
    "        blob_name=test_file,\n",
    "        locale=\"kn-IN\",\n",
    "        enable_diarization=False,  # Test without diarization first\n",
    "        poll_interval=3,\n",
    "        max_wait_time=300\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULT\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Duration: {result_no_diarization['duration']:.1f} seconds\")\n",
    "    print(f\"Cost: ${result_no_diarization['cost']:.4f}\")\n",
    "    print(f\"Segments: {len(result_no_diarization['segments'])}\")\n",
    "    print(f\"\\nTranscription text:\\n{result_no_diarization['text'][:500]}\")\n",
    "    \n",
    "    # Save result\n",
    "    output_file = output_dir / f\"{Path(test_file).stem}_no_diarization.json\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result_no_diarization, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úì Saved to: {output_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Single File WITH Diarization\n",
    "\n",
    "**Critical Test**: Does Azure support diarization for Kannada (kn-IN)?\n",
    "\n",
    "This is undocumented in Azure's official docs‚Äîwe're testing it empirically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TEST 2: Transcription WITH Diarization (Speaker Separation)\")\n",
    "print(\"=\"*80)\n",
    "print(\"Testing if Azure supports diarization for Kannada (kn-IN)...\\n\")\n",
    "\n",
    "try:\n",
    "    result_with_diarization = client.transcribe_file(\n",
    "        blob_name=test_file,\n",
    "        locale=\"kn-IN\",\n",
    "        enable_diarization=True,  # Enable speaker separation\n",
    "        min_speakers=2,  # Tutor + child\n",
    "        max_speakers=2,\n",
    "        poll_interval=3,\n",
    "        max_wait_time=300\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RESULT\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Duration: {result_with_diarization['duration']:.1f} seconds\")\n",
    "    print(f\"Cost: ${result_with_diarization['cost']:.4f}\")\n",
    "    print(f\"Segments: {len(result_with_diarization['segments'])}\")\n",
    "    \n",
    "    # Check if speaker info is present\n",
    "    has_speakers = any('speaker' in seg for seg in result_with_diarization['segments'])\n",
    "    if has_speakers:\n",
    "        print(\"\\nüéâ SUCCESS: Diarization works for Kannada!\")\n",
    "        print(\"\\nSpeaker breakdown:\")\n",
    "        speakers = {}\n",
    "        for seg in result_with_diarization['segments']:\n",
    "            speaker_id = seg.get('speaker', 'Unknown')\n",
    "            speakers[speaker_id] = speakers.get(speaker_id, 0) + 1\n",
    "        for speaker, count in speakers.items():\n",
    "            print(f\"  Speaker {speaker}: {count} segments\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: No speaker information in results\")\n",
    "        print(\"Diarization may not be supported for Kannada (kn-IN)\")\n",
    "    \n",
    "    print(f\"\\nTranscription text:\\n{result_with_diarization['text'][:500]}\")\n",
    "    \n",
    "    # Save result\n",
    "    output_file = output_dir / f\"{Path(test_file).stem}_with_diarization.json\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result_with_diarization, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"\\n‚úì Saved to: {output_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    print(\"\\nPossible reasons:\")\n",
    "    print(\"1. Diarization not supported for Kannada (kn-IN)\")\n",
    "    print(\"2. API version or region issue\")\n",
    "    print(\"3. Incorrect request parameters\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results: No Diarization vs. With Diarization\n",
    "\n",
    "Compare the two transcriptions to see if they differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'result_no_diarization' in locals() and 'result_with_diarization' in locals():\n",
    "    print(f\"\\nText identical: {result_no_diarization['text'] == result_with_diarization['text']}\")\n",
    "    print(f\"Segments (no diarization): {len(result_no_diarization['segments'])}\")\n",
    "    print(f\"Segments (with diarization): {len(result_with_diarization['segments'])}\")\n",
    "    \n",
    "    # Check if diarization added speaker info\n",
    "    has_speaker_info = any('speaker' in seg for seg in result_with_diarization['segments'])\n",
    "    print(f\"Speaker information present: {has_speaker_info}\")\n",
    "    \n",
    "    if has_speaker_info:\n",
    "        print(\"\\n‚úì Diarization is supported for Kannada!\")\n",
    "        print(\"Proceeding with batch processing using diarization.\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Diarization may not be supported for Kannada.\")\n",
    "        print(\"Will proceed with batch processing WITHOUT diarization.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Could not compare‚Äîone or both tests failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Batch Processing (All 40 Files)\n",
    "\n",
    "Based on the diarization test results, process all files.\n",
    "\n",
    "**Note**: This will take 20-40 minutes depending on Azure's processing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all audio files in blob storage\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Get blob list\n",
    "connection_string = os.getenv('AZURE_STORAGE_CONN_STR')\n",
    "container_name = os.getenv('AZURE_STORAGE_CONTAINER_NAME')\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# Get all blob names\n",
    "all_blobs = [blob.name for blob in container_client.list_blobs() if blob.name.endswith('.mp3')]\n",
    "\n",
    "print(f\"Found {len(all_blobs)} MP3 files in blob storage:\")\n",
    "for blob in sorted(all_blobs)[:5]:\n",
    "    print(f\"  - {blob}\")\n",
    "print(f\"  ... and {len(all_blobs) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine whether to use diarization based on Test 2\n",
    "use_diarization = False\n",
    "if 'result_with_diarization' in locals():\n",
    "    use_diarization = any('speaker' in seg for seg in result_with_diarization['segments'])\n",
    "\n",
    "print(f\"\\nBatch processing with diarization: {use_diarization}\")\n",
    "print(f\"Files to process: {len(all_blobs)}\")\n",
    "print(\"\\nThis will take approximately 20-40 minutes...\\n\")\n",
    "\n",
    "# Confirm before proceeding\n",
    "proceed = input(\"Proceed with batch processing? (yes/no): \")\n",
    "if proceed.lower() != 'yes':\n",
    "    print(\"Batch processing cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch process all files\n",
    "if proceed.lower() == 'yes':\n",
    "    results = []\n",
    "    failed_files = []\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"BATCH PROCESSING: {len(all_blobs)} files\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for idx, blob_name in enumerate(all_blobs, 1):\n",
    "        print(f\"\\n[{idx}/{len(all_blobs)}] {blob_name}\")\n",
    "        \n",
    "        # Check if already processed\n",
    "        output_file = output_dir / f\"{Path(blob_name).stem}_azure.json\"\n",
    "        if output_file.exists():\n",
    "            print(f\"  ‚äô Already processed, skipping\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            result = client.transcribe_file(\n",
    "                blob_name=blob_name,\n",
    "                locale=\"kn-IN\",\n",
    "                enable_diarization=use_diarization,\n",
    "                min_speakers=2,\n",
    "                max_speakers=2,\n",
    "                poll_interval=5,\n",
    "                max_wait_time=600\n",
    "            )\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            # Save individual result\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(result, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Failed: {e}\")\n",
    "            failed_files.append({'file': blob_name, 'error': str(e)})\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BATCH PROCESSING COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Successfully processed: {len(results)} files\")\n",
    "    print(f\"Failed: {len(failed_files)} files\")\n",
    "    \n",
    "    if results:\n",
    "        total_duration = sum(r['duration'] for r in results)\n",
    "        total_cost = sum(r['cost'] for r in results)\n",
    "        print(f\"\\nTotal audio processed: {total_duration / 3600:.2f} hours\")\n",
    "        print(f\"Total cost: ${total_cost:.2f}\")\n",
    "    \n",
    "    if failed_files:\n",
    "        print(\"\\nFailed files:\")\n",
    "        for fail in failed_files:\n",
    "            print(f\"  - {fail['file']}: {fail['error']}\")\n",
    "    \n",
    "    # Save batch summary\n",
    "    summary_file = output_dir / f\"batch_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'processed': len(results),\n",
    "            'failed': len(failed_files),\n",
    "            'total_duration_hours': total_duration / 3600 if results else 0,\n",
    "            'total_cost': total_cost if results else 0,\n",
    "            'diarization_enabled': use_diarization,\n",
    "            'failed_files': failed_files\n",
    "        }, f, indent=2)\n",
    "    print(f\"\\n‚úì Summary saved to: {summary_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Whisper Baseline\n",
    "\n",
    "Load a Whisper transcription and compare with Azure's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corresponding Whisper result\n",
    "whisper_dir = project_root / 'files' / 'transcriptions' / 'batch_whisper_gpt4o'\n",
    "whisper_file = whisper_dir / f\"{Path(test_file).stem}.json\"\n",
    "\n",
    "if whisper_file.exists() and 'result_no_diarization' in locals():\n",
    "    with open(whisper_file, 'r', encoding='utf-8') as f:\n",
    "        whisper_result = json.load(f)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"AZURE vs. WHISPER COMPARISON\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nFile: {test_file}\")\n",
    "    print(f\"\\nDuration:\")\n",
    "    print(f\"  Whisper: {whisper_result.get('duration', 0):.1f}s\")\n",
    "    print(f\"  Azure:   {result_no_diarization['duration']:.1f}s\")\n",
    "    \n",
    "    print(f\"\\nSegments:\")\n",
    "    print(f\"  Whisper: {len(whisper_result.get('segments', []))}\")\n",
    "    print(f\"  Azure:   {len(result_no_diarization['segments'])}\")\n",
    "    \n",
    "    print(f\"\\nCost:\")\n",
    "    print(f\"  Whisper: ${whisper_result.get('whisper_cost', 0):.4f}\")\n",
    "    print(f\"  Azure:   ${result_no_diarization['cost']:.4f}\")\n",
    "    \n",
    "    print(f\"\\nWhisper transcription (Kannada):\")\n",
    "    print(f\"  {whisper_result.get('kannada_full_text', '')[:200]}...\")\n",
    "    \n",
    "    print(f\"\\nAzure transcription (Kannada):\")\n",
    "    print(f\"  {result_no_diarization['text'][:200]}...\")\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  Note: Visual comparison only. Use WER/CER metrics for quantitative analysis.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Whisper baseline not found. Run batch_whisper_gpt4o notebook first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. ‚úÖ **Kannada Transcription**: Azure Speech Service supports kn-IN\n",
    "2. ‚ùì **Diarization**: Check results above to see if speaker separation works\n",
    "3. üí∞ **Cost**: Azure is ~3x more expensive than Whisper (~$9 vs. $3 for 9 hours)\n",
    "4. ‚è±Ô∏è **Speed**: Batch API is async‚Äîtakes longer than real-time\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Implement WER/CER evaluation** (notebook 11)\n",
    "   - Compare Azure vs. Whisper accuracy\n",
    "   - Evaluate on child speech segments (if diarization works)\n",
    "\n",
    "2. **Add AssemblyAI** for comparison\n",
    "   - Another Tier 1 STT provider with Kannada support\n",
    "\n",
    "3. **Process remaining 3 large files**\n",
    "   - Azure can handle 20-32 minute files (Whisper hit 25MB limit)\n",
    "\n",
    "4. **Decision point**: Best STT for Youth Impact\n",
    "   - Accuracy (WER/CER)\n",
    "   - Cost ($/hour)\n",
    "   - Features (diarization, latency)\n",
    "   - Infrastructure (already using Azure?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
