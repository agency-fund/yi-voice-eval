{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Whisper API + GPT-4o-mini Transliteration Pipeline\n",
    "\n",
    "This notebook tests the full pipeline using OpenAI only:\n",
    "1. Transcribe audio with OpenAI Whisper API (Kannada script)\n",
    "2. Transliterate to Roman script using OpenAI GPT-4o-mini\n",
    "3. Save both versions\n",
    "\n",
    "**Benefits of GPT-4o-mini approach:**\n",
    "- Single API provider (OpenAI) for both transcription + transliteration\n",
    "- Very low cost (~$3.27 for full 9-hour dataset)\n",
    "- Flexible prompting for custom romanization styles\n",
    "- Consistent phonetic transliteration\n",
    "\n",
    "**Refactored to use:**\n",
    "- `src/voice_eval/whisper_api.py`\n",
    "- `src/voice_eval/gpt_transliteration.py`\n",
    "- `src/voice_eval/storage.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from src.voice_eval.config import load_config\n",
    "from src.voice_eval.whisper_api import transcribe_audio, transcription_to_dict, estimate_cost\n",
    "from src.voice_eval.gpt_transliteration import transliterate_text, transliterate_segments\n",
    "from src.voice_eval.storage import write_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "print(\"âœ“ API keys loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "language = load_config('whisper', 'language')\n",
    "audio_dir = load_config('input', 'audio_dir')\n",
    "\n",
    "print(f\"Language: {language}\")\n",
    "print(f\"Audio directory: {audio_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick an MP3 file for testing\n",
    "test_file = f\"{audio_dir}/GHPS.  Bammanakatti.mp3\"\n",
    "print(f\"Test file: {test_file}\")\n",
    "\n",
    "# Check file size\n",
    "import os\n",
    "file_size_mb = os.path.getsize(test_file) / (1024 * 1024)\n",
    "print(f\"File size: {file_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Transcribe with Whisper API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: Transcribing with OpenAI Whisper API...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "transcript = transcribe_audio(\n",
    "    audio_path=test_file,\n",
    "    language=language,\n",
    "    response_format=\"verbose_json\",\n",
    "    timestamp_granularities=[\"segment\"]\n",
    ")\n",
    "\n",
    "whisper_cost = estimate_cost(transcript.duration)\n",
    "\n",
    "print(f\"âœ“ Transcription complete!\")\n",
    "print(f\"  Language detected: {transcript.language}\")\n",
    "print(f\"  Duration: {transcript.duration:.2f} seconds ({transcript.duration/60:.1f} minutes)\")\n",
    "print(f\"  Segments: {len(transcript.segments)}\")\n",
    "print(f\"  Cost: ${whisper_cost:.4f}\")\n",
    "print(f\"\\nFirst 200 chars (Kannada script):\\n{transcript.text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Transliterate Full Text with GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: Transliterating full text to Roman script...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "romanized_text, full_text_metrics = transliterate_text(\n",
    "    text=transcript.text,\n",
    "    source_language=\"Kannada\"\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Transliteration complete!\")\n",
    "print(f\"  Tokens used: {full_text_metrics['tokens']['total']}\")\n",
    "print(f\"  Latency: {full_text_metrics['latency_ms']:.0f}ms\")\n",
    "print(f\"  Cost: ${full_text_metrics['cost_usd']:.6f}\")\n",
    "print(f\"\\nFirst 200 chars (Romanized):\\n{romanized_text[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Transliterate Individual Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: Transliterating individual segments...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert segments to dictionaries\n",
    "segments_dict = transcription_to_dict(transcript)[\"segments\"]\n",
    "\n",
    "romanized_segments, segment_metrics = transliterate_segments(\n",
    "    segments=segments_dict,\n",
    "    text_field=\"text\",\n",
    "    source_language=\"Kannada\"\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ All {segment_metrics['total_segments']} segments transliterated!\")\n",
    "print(f\"  Total cost: ${segment_metrics['total_cost_usd']:.6f}\")\n",
    "print(f\"  Total tokens: {segment_metrics['total_tokens']:,}\")\n",
    "print(f\"  Total time: {segment_metrics['total_latency_ms']/1000:.1f}s\")\n",
    "print(f\"  Avg per segment: {segment_metrics['avg_latency_per_segment_ms']:.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Total Pipeline Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE COST BREAKDOWN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_cost = whisper_cost + segment_metrics['total_cost_usd']\n",
    "\n",
    "print(f\"\\nWhisper API (transcription):   ${whisper_cost:.6f}\")\n",
    "print(f\"GPT-4o-mini (full text):        ${full_text_metrics['cost_usd']:.6f}\")\n",
    "print(f\"GPT-4o-mini (segments):         ${segment_metrics['total_cost_usd']:.6f}\")\n",
    "print(f\"{'-'*60}\")\n",
    "print(f\"Total pipeline cost:            ${total_cost:.6f}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Cost per minute of audio:    ${total_cost / (transcript.duration/60):.6f}\")\n",
    "print(f\"ðŸ“Š Cost per character:           ${total_cost / len(transcript.text):.8f}\")\n",
    "\n",
    "# Extrapolate to full dataset\n",
    "dataset_duration_hours = 9.0\n",
    "dataset_cost_estimate = total_cost * (dataset_duration_hours * 60) / (transcript.duration / 60)\n",
    "print(f\"\\nðŸ’° Estimated cost for full dataset (9 hours): ${dataset_cost_estimate:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Save Combined Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: Saving results...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create combined response\n",
    "combined_response = {\n",
    "    \"metadata\": {\n",
    "        \"file\": test_file,\n",
    "        \"language\": transcript.language,\n",
    "        \"duration\": transcript.duration,\n",
    "        \"whisper_model\": \"whisper-1\",\n",
    "        \"transliteration_provider\": \"openai-gpt-4o-mini\",\n",
    "        \"costs_usd\": {\n",
    "            \"whisper_transcription\": whisper_cost,\n",
    "            \"gpt_transliteration_full_text\": full_text_metrics['cost_usd'],\n",
    "            \"gpt_transliteration_segments\": segment_metrics['total_cost_usd'],\n",
    "            \"total_pipeline\": total_cost\n",
    "        },\n",
    "        \"metrics\": {\n",
    "            \"total_tokens\": segment_metrics['total_tokens'],\n",
    "            \"total_segments\": segment_metrics['total_segments'],\n",
    "            \"processing_time_seconds\": segment_metrics['total_latency_ms'] / 1000\n",
    "        }\n",
    "    },\n",
    "    \"transcription\": {\n",
    "        \"text_kannada\": transcript.text,\n",
    "        \"text_romanized\": romanized_text\n",
    "    },\n",
    "    \"segments\": romanized_segments\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "output_path = write_file(\n",
    "    \"whisper_gpt4o_combined_response.json\",\n",
    "    json.dumps(combined_response, indent=2, ensure_ascii=False),\n",
    "    base_dir=\"files/transcriptions/whisper_gpt4o_test\"\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Combined results saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Display Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAMPLE SEGMENTS (First 3)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, seg in enumerate(romanized_segments[:3], 1):\n",
    "    print(f\"\\n[Segment {i}] {seg['start']:.2f}s â†’ {seg['end']:.2f}s\")\n",
    "    print(f\"  Kannada:    {seg['text'][:80]}...\" if len(seg['text']) > 80 else f\"  Kannada:    {seg['text']}\")\n",
    "    print(f\"  Romanized:  {seg['text_romanized'][:80]}...\" if len(seg.get('text_romanized', '')) > 80 else f\"  Romanized:  {seg.get('text_romanized', 'N/A')}\")\n",
    "\n",
    "print(f\"\\n... ({len(romanized_segments) - 3} more segments)\")\n",
    "print(\"\\nâœ… Pipeline test successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the **OpenAI-only pipeline** using:\n",
    "- Whisper API for transcription (Kannada native script)\n",
    "- GPT-4o-mini for transliteration (Roman script)\n",
    "\n",
    "**Key advantages:**\n",
    "1. **Single API provider** - Simplified integration and billing\n",
    "2. **Low cost** - Estimated ~$3.27 for entire 9-hour dataset\n",
    "3. **Consistent quality** - Phonetic romanization with diacritics\n",
    "4. **Flexible** - Can customize romanization style via prompts\n",
    "\n",
    "**Ready for batch processing!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yi-voice-eval",
   "language": "python",
   "name": "yi-voice-eval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
